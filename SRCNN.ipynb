{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SRCNN_new",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrR1r9tUmhKZ"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "import cv2\n",
        "import copy\n",
        "from PIL import ImageFilter\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_I6w7QUmnF0"
      },
      "source": [
        "SCALE = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqLXvJx6mpqB"
      },
      "source": [
        "class HeadDataset(Dataset):\n",
        "    def __init__(self, files, scale=SCALE, stride=30):\n",
        "        # self.files = files\n",
        "        self.scale = scale\n",
        "        # self.files = []\n",
        "        image_windows = []\n",
        "        for image in files:\n",
        "            img = cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2RGB)\n",
        "            h,w,c = img.shape\n",
        "            for i in range(0,h-stride,stride):\n",
        "                for j in range(0,w-stride,stride):\n",
        "                    image_windows.append(img[i:i+stride, j:j+stride, :])\n",
        "        self.files = image_windows\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "\n",
        "           \n",
        "    def __getitem__(self, idx):\n",
        "        scale = self.scale\n",
        "        hr = Image.fromarray(self.files[idx])\n",
        "        hr_width = (hr.width // scale) * scale\n",
        "        hr_height = (hr.height // scale) * scale\n",
        "        lr = hr.filter(ImageFilter.GaussianBlur(radius=2))\n",
        "        lr = lr.resize((hr_width // scale, hr_height // scale), resample=Image.BICUBIC)\n",
        "        lr = lr.resize((lr.width * scale, lr.height * scale), resample=Image.BICUBIC)\n",
        "        hr = np.moveaxis(np.array(hr).astype(np.float32), 2, 0)\n",
        "        lr = np.moveaxis(np.array(lr).astype(np.float32), 2, 0)\n",
        "        return lr, hr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvLsQQIEEKxC"
      },
      "source": [
        "train_folder_regex = './Train/*'\n",
        "train_dataset = HeadDataset(glob.glob(train_folder_regex))\n",
        "train_data = DataLoader(dataset=train_dataset,batch_size=16,shuffle=True,num_workers=8,pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4FApyOOELsN"
      },
      "source": [
        "test_data = []\n",
        "for image in glob.glob('./Test/*/*.bmp'):\n",
        "    img = cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2RGB)\n",
        "    img = torch.tensor(np.array([np.moveaxis(np.array(img).astype(np.float32), 2, 0)]))\n",
        "    test_data.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}